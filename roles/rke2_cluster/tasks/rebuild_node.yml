---
- name: Select Delegation Target with Fallback
  block:
    - name: Try Primary Delegation
      ansible.builtin.set_fact:
        delegation_target: >-
          {{ 
            groups['control_plane_nodes'] | 
            reject('equalto', inventory_hostname) | 
            first 
          }}
      when: groups['control_plane_nodes'] | length > 1

    - name: Warn About Limited Delegation Options
      ansible.builtin.debug:
        msg: "Warning: Limited delegation targets available"
      when: groups['control_plane_nodes'] | length <= 1
        
    - name: Manual Intervention Recommendation
      ansible.builtin.fail:
        msg: "Cannot safely delegate cluster operations. Manual intervention required."
      when: groups['control_plane_nodes'] | length <= 1

- name: Set common variables
  ansible.builtin.set_fact:
    etcd_base_cmd: >-
      {{ kubectl.command }} exec -n kube-system 
      etcd-{{ groups['control_plane_nodes'][0] | lower }} 
      -- etcdctl {{ etcdctl_params }}
    rke2_dirs:
      - "{{ paths.rke2.config }}"
      - "{{ paths.rke2.bin }}"
      - "{{ paths.system.bin }}"
    rebuilding_first_node: "{{ inventory_hostname == groups['control_plane_nodes'][0] }}"

- name: Verify RKE2 version is defined
  ansible.builtin.assert:
    that: rke2_version is defined
    fail_msg: "RKE2 version must be defined in inventory"
    success_msg: "Using RKE2 version {{ rke2_version }}"

- name: Check if RKE2 is already installed
  ansible.builtin.stat:
    path: /usr/local/bin/rke2
  register: rke2_binary_check

- name: Calculate available root filesystem space
  ansible.builtin.set_fact:
    root_available_space: "{{ (ansible_mounts | selectattr('mount', 'equalto', '/') | map(attribute='size_available') | first / 1024 / 1024) | round(2) }}"

- name: Determine space requirement
  ansible.builtin.set_fact:
    required_space: >-
      {{
        1500 if rke2_binary_check.stat.exists
        else 3400
      }}
  vars:
    # Space requirements in MB:
    # - New installation: ~3.4GB
    # - Rebuild with existing installation: ~1.5GB

- name: Validate disk space availability
  ansible.builtin.assert:
    that: "root_available_space | float >= required_space | float"
    fail_msg: >-
      Insufficient disk space for RKE2 {{ 'rebuild' if rke2_binary_check.stat.exists else 'installation' }}.
      Required: At least {{ required_space }}MB for {{ 'rebuild' if rke2_binary_check.stat.exists else 'new installation' }}
      Available space: {{ root_available_space }}MB
    success_msg: "Sufficient disk space available for RKE2 {{ 'rebuild' if rke2_binary_check.stat.exists else 'installation' }}"

- name: Include preflight checks
  ansible.builtin.include_tasks: preflight.yml

- name: Verify cluster health before rebuild
  ansible.builtin.include_tasks: verify_cluster.yml
  when: inventory_hostname != groups['control_plane_nodes'][0]

- name: Get existing token from control plane
  ansible.builtin.slurp:
    src: /etc/rancher/rke2/config.yaml
  register: existing_config
  delegate_to: "{{ delegation_target }}"
  become: true

- name: Check if node exists in cluster
  ansible.builtin.shell: |
    {{ kubectl.command }} get node {{ inventory_hostname | lower }} --no-headers
  register: node_exists
  delegate_to: "{{ delegation_target }}"
  become: true
  failed_when: false
  changed_when: false

- name: Check node status in cluster
  ansible.builtin.shell: |
    {{ kubectl.command }} get node {{ inventory_hostname | lower }} -o jsonpath='{.spec.unschedulable},{.status.conditions[?(@.type=="Ready")].status}'
  register: node_status
  delegate_to: "{{ delegation_target }}"
  become: true
  failed_when: false
  changed_when: false

- name: Set node status facts
  ansible.builtin.set_fact:
    node_exists: "{{ node_status.rc == 0 }}"
    node_cordoned: "{{ 'true' in (node_status.stdout.split(',')[0] | default('')) }}"
    node_ready: "{{ 'True' in (node_status.stdout.split(',')[1] | default('')) }}"

- name: Debug node status
  ansible.builtin.debug:
    msg: 
      - "Node exists: {{ node_exists }}"
      - "Node cordoned: {{ node_cordoned }}"
      - "Node ready: {{ node_ready }}"

- name: Cordon node before rebuild
  ansible.builtin.command: >-
    {{ kubectl.command }} cordon {{ inventory_hostname | lower }}
  delegate_to: "{{ delegation_target }}"
  become: true
  when: 
    - node_exists
    - not node_cordoned
    - node_ready
  register: cordon_result
  failed_when: false

- name: Include drain node tasks
  ansible.builtin.include_tasks: drain_node.yml
  when: 
    - node_exists
    - node_ready
    - not node_cordoned
    - cordon_result is not failed

- name: Ensure RKE2 directories exist
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: "0755"
  become: true
  loop: "{{ rke2_dirs }}"

- name: Debug etcd member list
  ansible.builtin.shell: |
    {{ etcd_base_cmd }} member list | column -t
  register: etcd_members
  delegate_to: "{{ delegation_target }}"
  changed_when: false

- name: Display etcd members
  ansible.builtin.debug:
    msg: |
      Current etcd members:
      {{ etcd_members.stdout_lines | join('\n') }}

- name: Get etcd member ID for the node
  ansible.builtin.shell: |
    {{ kube_cmd }} exec -n kube-system etcd-{{ delegation_target | lower }} -- etcdctl {{ etcdctl_params }} member list | grep {{ inventory_hostname }} | cut -d',' -f1
  register: etcd_member_id
  delegate_to: "{{ delegation_target }}"
  become: true
  when: inventory_hostname in groups['control_plane_nodes']

- name: Remove etcd member
  ansible.builtin.shell: "{{ etcd_base_cmd }} member remove {{ etcd_member_id.stdout }}"
  delegate_to: "{{ delegation_target }}"
  become: true
  when: 
    - inventory_hostname in groups['control_plane_nodes']
    - etcd_member_id.stdout is defined
    - etcd_member_id.stdout != ""

- name: Verify etcd member removal
  block:
    - name: Check current etcd members
      ansible.builtin.shell: |
        {{ kube_cmd }} exec -n kube-system etcd-{{ delegation_target | lower }} -- etcdctl {{ etcdctl_params }} member list | column -t
      register: current_etcd_members
      delegate_to: "{{ delegation_target }}"
      changed_when: false

    - name: Display current etcd members during verification
      ansible.builtin.debug:
        msg: |
          Verifying etcd member removal for {{ inventory_hostname }}
          Current etcd members:
          {{ current_etcd_members.stdout_lines | join('\n') }}

    - name: Verify member is removed
      ansible.builtin.shell: |
        {{ kube_cmd }} exec -n kube-system etcd-{{ delegation_target | lower }} -- etcdctl {{ etcdctl_params }} member list | grep -v {{ inventory_hostname }}
      register: etcd_members
      until: etcd_members.rc == 0
      retries: 30
      delay: 10
      delegate_to: "{{ delegation_target }}"
      changed_when: false

- name: Skip etcd verification
  ansible.builtin.debug:
    msg: "Skipping etcd verification - node {{ inventory_hostname }} not found in etcd member list"
  when: inventory_hostname in groups['control_plane_nodes'] and etcd_member_id.stdout == ""

- name: Fail if node still exists in etcd
  ansible.builtin.fail:
    msg: "Node {{ inventory_hostname }} still exists in etcd member list"
  when:
    - inventory_hostname in groups['control_plane_nodes']
    - etcd_member_id.stdout is defined
    - etcd_member_id.stdout != ""
    - inventory_hostname | lower in (etcd_member_list.stdout | default(''))

- name: Delete node from Kubernetes
  ansible.builtin.shell: "{{ kube_cmd }} delete node {{ inventory_hostname | lower }}"
  delegate_to: "{{ delegation_target }}"
  become: true
  failed_when: false
  when: inventory_hostname != groups['control_plane_nodes'][0]

- name: Verify node removal from Kubernetes
  ansible.builtin.shell: "{{ kube_cmd }} get node {{ inventory_hostname | lower }}"
  delegate_to: "{{ delegation_target }}"
  become: true
  register: node_check
  until: node_check.rc == 1 or node_check.stderr is search("not found")
  retries: 6
  delay: 10
  changed_when: false
  failed_when: false
  when: inventory_hostname != groups['control_plane_nodes'][0]

- name: Check for uninstall scripts
  ansible.builtin.stat:
    path: "/usr/local/bin/{{ item }}"
  register: script_check
  loop:
    - rke2-uninstall.sh
    - rke2-killall.sh
  become: true

- name: Uninstall RKE2 if scripts exist
  ansible.builtin.shell: |
    /usr/local/bin/rke2-killall.sh
    sleep 5
    /usr/local/bin/rke2-killall.sh
    sleep 5
    /usr/local/bin/rke2-uninstall.sh
  when: 
    - script_check.results is defined
    - script_check.results | selectattr('stat.exists') | list | length == 2
  become: true

- name: Ensure RKE2 directories exist after uninstall
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: '0755'
    owner: root
    group: root
  with_items: "{{ rke2_dirs }}"
  become: true

- name: Extract token from existing config
  ansible.builtin.shell: |
    grep "token:" {{ paths.rke2.config }}/config.yaml | awk '{print $2}'
  register: token_extract
  delegate_to: "{{ delegation_target }}"
  become: true
  changed_when: false

- name: Set token fact
  ansible.builtin.set_fact:
    rke2_token: "{{ token_extract.stdout }}"

- name: Configure node
  ansible.builtin.template:
    src: config.yaml.j2
    dest: "{{ paths.rke2.config }}/config.yaml"
    mode: "0644"
  vars:
    node_token: "{{ rke2_token }}"
  become: true

- name: Check network connectivity to RKE2 documentation
  ansible.builtin.uri:
    url: https://docs.rke2.io/
    method: GET
    timeout: 30
  register: rke2_docs_check
  failed_when: false
  become: true

- name: Fail if RKE2 documentation site is unreachable
  ansible.builtin.fail:
    msg: "Unable to reach RKE2 documentation site. Network connectivity issue detected."
  when: rke2_docs_check.status != 200

- name: Include airgap setup
  ansible.builtin.include_tasks: airgap/main.yml
  when: airgap_install | default(false) | bool

- name: Install RKE2
  ansible.builtin.shell: |
    mkdir -p /usr/local/bin
    curl -sfL https://get.rke2.io | INSTALL_RKE2_VERSION="{{ rke2_release }}" sh -
  args:
    creates: /usr/local/bin/rke2
  register: rke2_install_result

- name: Extract RKE2 version
  ansible.builtin.set_fact:
    rke2_version_clean: "{{ rke2_version.stdout | default(rke2_version) }}"

- name: Set version directory path
  ansible.builtin.set_fact:
    version_dir: "{{ lookup('env', 'HOME') }}/Downloads/rke2-images/{{ rke2_version_clean }}"

- name: Include airgap verification
  ansible.builtin.include_tasks: "{{ role_path }}/tasks/verify_airgap.yml"
  when: airgap_install | default(false) | bool

- name: Include airgap image tasks
  ansible.builtin.include_tasks: "{{ role_path }}/tasks/airgap_images.yml"
  when: airgap_install | default(false) | bool

- name: Map architecture to RKE2 format
  ansible.builtin.set_fact:
    rke2_arch: >-
      {{
        'amd64' if ansible_architecture == 'x86_64'
        else 'arm64' if ansible_architecture in ['aarch64', 'arm64']
        else ansible_architecture
      }}

- name: Ensure airgap images directory exists on remote
  ansible.builtin.file:
    path: "{{ airgap.paths.images_dir }}"
    state: directory
    mode: '0755'
    owner: root
    group: root
  become: true

- name: Copy airgap images using standard copy
  ansible.builtin.copy:
    src: "{{ version_dir }}/rke2-images.linux-{{ rke2_arch }}.tar.zst"
    dest: "{{ airgap.paths.images_dir }}/rke2-images.linux-{{ rke2_arch }}.tar.zst"
    mode: '0644'
    owner: root
    group: root
  become: true

- name: Set file permissions
  ansible.builtin.file:
    path: "{{ airgap.paths.images_dir }}/rke2-images.linux-{{ rke2_arch }}.tar.zst"
    mode: '0644'
    owner: root
    group: root
  become: true
  when: airgap_install | default(false) | bool

- name: Configure RKE2 registries
  ansible.builtin.copy:
    dest: "/etc/rancher/rke2/registries.yaml"
    content: |
      mirrors:
        "*":
    mode: '0644'
    owner: root
    group: root
    
- name: Start RKE2 service
  ansible.builtin.systemd:
    name: "rke2-{{ 'server' if inventory_hostname in groups['control_plane_nodes'] else 'agent' }}"
    state: started
    enabled: true
  become: true

- name: Wait for node to appear in cluster
  ansible.builtin.shell: |
    {{ kube_cmd }} get nodes {{ inventory_hostname | lower }} -o name
  register: node_exists
  until: node_exists.rc == 0
  retries: 30
  delay: 10
  changed_when: false
  delegate_to: "{{ delegation_target }}"
  become: true

- name: Wait for node to be ready
  block:
    - name: Check kube-system pods readiness on node
      ansible.builtin.shell: |
        {{ kube_cmd }} get pods -n kube-system --field-selector spec.nodeName={{ inventory_hostname | lower }} -o jsonpath='{.items[*].status.phase}' | tr ' ' '\n' | grep -v "Running" | true
      register: pod_status
      until: pod_status.stdout == ""
      retries: "{{ 60 if rebuilding_first_node else 30 }}"
      delay: "{{ 20 if rebuilding_first_node else 10 }}"
      delegate_to: "{{ delegation_target }}"
      changed_when: false

    - name: Display error details on failure
      ansible.builtin.fail:
        msg: "Not all kube-system pods are running on node {{ inventory_hostname }}"
      when: pod_status.stdout != ""

    - name: Display node status
      ansible.builtin.debug:
        msg: "All kube-system pods are running on node {{ inventory_hostname }}"
      when: rebuilding_first_node

    - name: Wait additional time for first control plane stabilization
      when: rebuilding_first_node
      ansible.builtin.pause:
        seconds: 120

- name: Show node status
  ansible.builtin.shell: |
    {{ kubectl.command }} get nodes {{ inventory_hostname | lower }} -o wide
  register: node_status
  changed_when: false
  delegate_to: "{{ delegation_target }}"
  become: true
  when: node_exists.rc == 0

- name: Wait for all control plane nodes except current node
  shell: |
    {{ kubectl.command }} get nodes --selector='node-role.kubernetes.io/control-plane' \
      --no-headers | grep -v {{ inventory_hostname }} | grep Ready
  register: control_plane_nodes
  until: control_plane_nodes.rc == 0
  retries: 30
  delay: 10
  delegate_to: "{{ delegation_target }}"

- name: Wait for etcd health after node removal
  when: inventory_hostname in groups['control_plane_nodes']
  ansible.builtin.command:
    cmd: "{{ etcd_base_cmd }} endpoint health"
  register: etcd_health
  until: etcd_health.rc == 0
  retries: 30
  delay: 10
  delegate_to: "{{ delegation_target }}"
  changed_when: false

- name: Wait for node to be ready after rebuild
  block:
    - name: Check node readiness status
      ansible.builtin.shell: |
        set -o pipefail
        {{ kubectl.command }} get nodes {{ inventory_hostname | lower }} \
          -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}'
      args:
        executable: /bin/bash
      register: node_ready
      until: node_ready.stdout == "True"
      retries: "{{ retry_extended }}"
      delay: "{{ retry_delay }}"
      delegate_to: "{{ delegation_target }}"
      become: true
      changed_when: false

    - name: Display final node status
      ansible.builtin.debug:
        msg:
          - "Node: {{ inventory_hostname }}"
          - "Status: Ready"
          - "Verification Time: {{ ansible_date_time.iso8601 }}"
      when: node_ready.stdout == "True"

  rescue:
    - name: Collect node diagnostics
      ansible.builtin.shell: |
        {{ kubectl.command }} describe node {{ inventory_hostname | lower }}
      register: node_diagnostics
      delegate_to: "{{ delegation_target }}"
      become: true
      changed_when: false

    - name: Display node failure details
      ansible.builtin.fail:
        msg: |
          Node failed to reach Ready state after rebuild
          Time: {{ ansible_date_time.iso8601 }}
          Details:
          {{ node_diagnostics.stdout }}

- name: Copy airgap images after installation
  ansible.builtin.copy:
    src: "{{ version_dir }}/rke2-images.linux-{{ rke2_arch }}.tar.zst"
    dest: "/var/lib/rancher/rke2/agent/images/"
    mode: "0644"
    owner: root
    group: root
  when: rke2_install_result.changed | default(false)


